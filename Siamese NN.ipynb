{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.models import *\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupDF = pd.read_csv('Data/groupDF_clean.csv', index_col=0)\n",
    "groupDF.drop('rem_company_id_dummy', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcols = groupDF.columns.tolist()\n",
    "Xcols.remove('payroll_ind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pair = groupDF.drop('payroll_ind', axis=1)\n",
    "Y_pair = groupDF.drop(Xcols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05009019009296517"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_pair[Y_pair['payroll_ind']==1])/(len(X_pair[Y_pair['payroll_ind']==1])+len(X_pair[Y_pair['payroll_ind']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_train_dataset(Dataset):\n",
    "    '''\n",
    "    Makes dataset with pairs of examples\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, X, Y):\n",
    "        self.X_train = X\n",
    "        self.Y_train = Y \n",
    "        self.indices = self.X_train.index\n",
    "        self.indices_01 = (self.X_train[self.Y_train['payroll_ind']==0].index, self.X_train[self.Y_train['payroll_ind']==1].index)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        pair1 = random.choice(self.indices)                    #### MOST OF PAIR1 will be from class == 0\n",
    "        Y1 = self.Y_train.loc[random.choice(self.X_train.index)].values[0]  # random.randint(0, 1) # since there is class imbalance??\n",
    "        \n",
    "        # Approx 50% of images should be same class\n",
    "        same_class = random.randint(0, 1)\n",
    "        if same_class:\n",
    "            Y2 = Y1\n",
    "        else:\n",
    "            Y2 = abs(1-Y1)\n",
    "        pair2 = random.choice(self.indices_01[Y2])\n",
    "        \n",
    "        X1 = torch.from_numpy(self.X_train.loc[pair1].values.reshape(1, -1))\n",
    "        X2 = torch.from_numpy(self.X_train.loc[pair2].values.reshape(1, -1))\n",
    "        label = torch.from_numpy(np.array([Y1!=Y2], dtype=np.float32))        # == or != ?? \n",
    "\n",
    "        return X1, X2, label \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_train/2)\n",
    "#         return len(self.X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_siam = create_train_dataset(X=X_pair, Y=Y_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visDL = DataLoader(train_data_siam, shuffle=True, num_workers=0, batch_size=8)\n",
    "dataiter = iter(visDL)\n",
    "example_batch = next(dataiter)\n",
    "(example_batch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNN(nn.Module):\n",
    "    def __init__(self, input_size=29, output_size=8):\n",
    "        super(SiameseNN, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)  # hidden layer 1\n",
    "        self.fc3 = nn.Linear(32, 16)  # hidden layer 2\n",
    "        self.fc4 = nn.Linear(16, 8)   \n",
    "\n",
    "    def forward_single(self, x):\n",
    "        \n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.tanh(self.fc3(x))\n",
    "        x = F.tanh(self.fc4(x))\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        output1 = self.forward_single(x1)\n",
    "        output2 = self.forward_single(x2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mahalanobis dist instea of euc\n",
    "- triplet loss\n",
    "- strategies for sampling -> easy, hard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, output1, output2, label):\n",
    "        euc_dist = F.pairwise_distance(output1, output2, keepdim=True)     \n",
    "        loss = torch.mean((1-label)*torch.pow(euc_dist, 2) + label*torch.pow(torch.clamp(self.margin-euc_dist, min=0.0), 2))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_siam = create_train_dataset(X=X_pair, Y=Y_pair)\n",
    "train_loader = DataLoader(train_data_siam, shuffle=True, num_workers=0, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNN().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ContrastiveLoss()\n",
    "opt = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithy\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Loss: 0.17005336027964948, n_examples: 8000\n",
      "Epoch: 0  Loss: 0.16926892301626503, n_examples: 16000\n",
      "Epoch: 0  Loss: 0.1685751283019781, n_examples: 24000\n",
      "Epoch: 0  Loss: 0.1678500998057425, n_examples: 32000\n",
      "Epoch: 0  Loss: 0.16735312193036078, n_examples: 40000\n",
      "Epoch: 0  Loss: 0.16674312579755982, n_examples: 48000\n",
      "Epoch: 0  Loss: 0.1664337523324149, n_examples: 56000\n",
      "Epoch: 0  Loss: 0.16617579875467345, n_examples: 64000\n",
      "Epoch: 0  Loss: 0.16592530180596643, n_examples: 72000\n",
      "Epoch: 0  Loss: 0.16564967766925692, n_examples: 80000\n",
      "Epoch: 0  Loss: 0.16525209508226676, n_examples: 88000\n",
      "Epoch: 0  Loss: 0.16510247074378034, n_examples: 96000\n",
      "Epoch: 0  Loss: 0.164979709174484, n_examples: 104000\n",
      "Epoch: 0  Loss: 0.16474007440278574, n_examples: 112000\n",
      "Epoch: 0  Loss: 0.16453054952497284, n_examples: 120000\n",
      "Epoch: 0  Loss: 0.16435526292049327, n_examples: 128000\n",
      "Epoch: 0  Loss: 0.164240378100425, n_examples: 136000\n",
      "Epoch: 0  Loss: 0.16408268514999913, n_examples: 144000\n",
      "Epoch: 0  Loss: 0.16395502743830806, n_examples: 152000\n",
      "Epoch: 0  Loss: 0.1637663144382648, n_examples: 160000\n",
      "Epoch: 0  Loss: 0.1636299678202541, n_examples: 168000\n",
      "Epoch: 0  Loss: 0.16351099683344364, n_examples: 176000\n",
      "Epoch: 0  Loss: 0.1634412060033368, n_examples: 184000\n",
      "Epoch: 0  Loss: 0.16328897223155944, n_examples: 192000\n",
      "Epoch: 0  Loss: 0.16322466735959054, n_examples: 200000\n",
      "Epoch: 0  Loss: 0.16303676089830696, n_examples: 208000\n",
      "Epoch: 0  Loss: 0.1629724768901037, n_examples: 216000\n",
      "Epoch: 0  Loss: 0.16284779784535722, n_examples: 224000\n",
      "Epoch: 0  Loss: 0.16278213400843328, n_examples: 232000\n",
      "Epoch: 0  Loss: 0.16275562047585845, n_examples: 240000\n",
      "Epoch: 0  Loss: 0.16276437501417051, n_examples: 248000\n",
      "Epoch: 0  Loss: 0.16269743823536556, n_examples: 256000\n",
      "Epoch: 0  Loss: 0.16262221193604284, n_examples: 264000\n",
      "Epoch: 0  Loss: 0.16250858858794742, n_examples: 272000\n",
      "Epoch: 0  Loss: 0.16251122852146094, n_examples: 280000\n",
      "Epoch: 0  Loss: 0.16249933976537756, n_examples: 288000\n",
      "Epoch: 0  Loss: 0.16250711106340326, n_examples: 296000\n",
      "Epoch: 0  Loss: 0.16252386192269133, n_examples: 304000\n",
      "Epoch: 0  Loss: 0.16249730369073745, n_examples: 312000\n",
      "Epoch: 0  Loss: 0.16242511631248052, n_examples: 320000\n",
      "Epoch: 0  Loss: 0.1624529593865637, n_examples: 328000\n",
      "Epoch: 0  Loss: 0.1624248243192255, n_examples: 336000\n",
      "Epoch: 0  Loss: 0.1624030786316712, n_examples: 344000\n",
      "Epoch: 0  Loss: 0.1622971930120098, n_examples: 352000\n",
      "Epoch: 0  Loss: 0.16226272236462683, n_examples: 360000\n",
      "Epoch: 0  Loss: 0.16221992940307878, n_examples: 368000\n",
      "Epoch: 0  Loss: 0.16219024026863516, n_examples: 376000\n",
      "Epoch: 0  Loss: 0.16217799503199395, n_examples: 381976\n",
      "Epoch: 1  Loss: 0.16068399163149297, n_examples: 8000\n",
      "Epoch: 1  Loss: 0.16062777025066316, n_examples: 16000\n",
      "Epoch: 1  Loss: 0.16025660607467096, n_examples: 24000\n",
      "Epoch: 1  Loss: 0.16040747882192954, n_examples: 32000\n",
      "Epoch: 1  Loss: 0.16040053303912283, n_examples: 40000\n",
      "Epoch: 1  Loss: 0.16062122066505252, n_examples: 48000\n",
      "Epoch: 1  Loss: 0.16070438912670526, n_examples: 56000\n",
      "Epoch: 1  Loss: 0.16083733132714406, n_examples: 64000\n",
      "Epoch: 1  Loss: 0.16077629034262564, n_examples: 72000\n",
      "Epoch: 1  Loss: 0.16054262421429158, n_examples: 80000\n",
      "Epoch: 1  Loss: 0.16062483609704808, n_examples: 88000\n",
      "Epoch: 1  Loss: 0.16063221038288125, n_examples: 96000\n",
      "Epoch: 1  Loss: 0.16071489004246317, n_examples: 104000\n",
      "Epoch: 1  Loss: 0.16078656083185758, n_examples: 112000\n",
      "Epoch: 1  Loss: 0.16072461014961203, n_examples: 120000\n",
      "Epoch: 1  Loss: 0.16078692979342304, n_examples: 128000\n",
      "Epoch: 1  Loss: 0.16073460590806515, n_examples: 136000\n",
      "Epoch: 1  Loss: 0.16064531480614097, n_examples: 144000\n",
      "Epoch: 1  Loss: 0.1605504014175385, n_examples: 152000\n",
      "Epoch: 1  Loss: 0.16050874315723776, n_examples: 160000\n",
      "Epoch: 1  Loss: 0.16049072803716574, n_examples: 168000\n",
      "Epoch: 1  Loss: 0.16042357696669007, n_examples: 176000\n",
      "Epoch: 1  Loss: 0.16041588251203623, n_examples: 184000\n",
      "Epoch: 1  Loss: 0.16038012527658915, n_examples: 192000\n",
      "Epoch: 1  Loss: 0.1603370894832164, n_examples: 200000\n",
      "Epoch: 1  Loss: 0.16036386310230366, n_examples: 208000\n",
      "Epoch: 1  Loss: 0.16041640224211193, n_examples: 216000\n",
      "Epoch: 1  Loss: 0.16036328624667867, n_examples: 224000\n",
      "Epoch: 1  Loss: 0.1603755976602692, n_examples: 232000\n",
      "Epoch: 1  Loss: 0.16045594127805282, n_examples: 240000\n",
      "Epoch: 1  Loss: 0.16057325827144087, n_examples: 248000\n",
      "Epoch: 1  Loss: 0.16054239761154168, n_examples: 256000\n",
      "Epoch: 1  Loss: 0.1605559558660695, n_examples: 264000\n",
      "Epoch: 1  Loss: 0.16052995177643264, n_examples: 272000\n",
      "Epoch: 1  Loss: 0.16057340950114388, n_examples: 280000\n",
      "Epoch: 1  Loss: 0.16057791752761436, n_examples: 288000\n",
      "Epoch: 1  Loss: 0.16052564594894647, n_examples: 296000\n",
      "Epoch: 1  Loss: 0.16052889789013486, n_examples: 304000\n",
      "Epoch: 1  Loss: 0.16048790947739514, n_examples: 312000\n"
     ]
    }
   ],
   "source": [
    "loss_ep = []\n",
    "for epoch in range(0, 100):\n",
    "    loss_iter = 0\n",
    "    count = 1\n",
    "    for data in train_loader:\n",
    "        X1, X2, label = data\n",
    "        X1, X2, label = X1.type(torch.FloatTensor), X2.type(torch.FloatTensor), label.type(torch.FloatTensor)\n",
    "        X1, X2, label = X1.cuda(), X2.cuda(), label.cuda()\n",
    "        opt.zero_grad()\n",
    "        output1, output2 = net(X1, X2)\n",
    "        loss = criterion(output1, output2, label)\n",
    "        loss.backward()\n",
    "        loss_iter += loss.item()\n",
    "        opt.step()\n",
    "        \n",
    "        if count%1000==0:\n",
    "            print('Epoch: {0}  Loss: {1}, n_examples: {2}'.format(epoch, loss_iter/(8*count), 8*count))\n",
    "        count += 1\n",
    "    print('Epoch: {0}  Loss: {1}, n_examples: {2}'.format(epoch, loss_iter/(8*len(train_loader)), (8*len(train_loader))))\n",
    "    loss_ep.append(loss_iter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
